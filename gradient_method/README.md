#Grandient method

##1.Summary

    It is the simplest and the most commonly optimization method. It is easy to achieve. Only when the objective 
    
    function is a convex function, the solution of the gradient descent method is a global solution. Usually, the 

    the solution of the gradient descent method isn't a global solution.
    
##2.Process
    
    BGD(Batch gradient descent method):
    
    
    SGD(Stochastic gradient descent method):
    
##3.Experiment

    The number of sample is 100, The dimension is 3.
<table>
<tr>
<td> name </td> <td>iteration number</td> <td>calculation time</td>
</tr>
</table>
    
    
